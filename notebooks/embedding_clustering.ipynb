{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "s3RLD3A1V8Vu"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "kW5M_syOWKM4"
   },
   "outputs": [],
   "source": [
    "embeddings = np.load(r\"C:\\Users\\Florian Moga\\Desktop\\Code\\numpy_embeddings.npy\")\n",
    "classes, samples, vector_size = embeddings.shape\n",
    "class_labels = np.empty((classes, samples), dtype=int)\n",
    "for i in range(len(class_labels)):\n",
    "    class_labels[i] = np.full(samples, i)\n",
    "\n",
    "class_sample_combination = [(x, y) for x in range(classes) for y in range(samples)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s2UcaE7l36Sq"
   },
   "outputs": [],
   "source": [
    "def choose_n_classes(n):\n",
    "    n_embeddings = np.empty((classes, samples, vector_size))\n",
    "    n_class_labels = np.empty((n, samples), dtype=int)\n",
    "\n",
    "    class_range = list(range(classes))\n",
    "    n_classes = []\n",
    "\n",
    "    i = 0\n",
    "    while i < n:\n",
    "        random_class = random.choice(class_range)\n",
    "        class_range.remove(random_class)\n",
    "        n_classes.append(random_class)\n",
    "\n",
    "        n_embeddings[random_class] = embeddings[random_class]\n",
    "        n_class_labels[i] = class_labels[random_class]\n",
    "\n",
    "        i+=1\n",
    "\n",
    "    n_class_sample_combination = [(x, y) for x in n_classes for y in range(samples)]\n",
    "\n",
    "    return n_embeddings, n_class_labels, n_class_sample_combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "I_x-wAhwWX09"
   },
   "outputs": [],
   "source": [
    "def cosine_sim(a, b):\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    norm_ab = norm_a * norm_b\n",
    "    if norm_ab < 1e-8:\n",
    "        norm_ab = 1e-8\n",
    "    return np.dot(a, b)/norm_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "XgFS9vaKWQ_f"
   },
   "outputs": [],
   "source": [
    "def get_mean(arr):\n",
    "    return(np.mean(arr, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "LEkbTQQAYKH-"
   },
   "outputs": [],
   "source": [
    "def cluster_no_finetuning(thresh, choose_n = False, n=0):\n",
    "\n",
    "    if choose_n != False:\n",
    "        n_embeddings, _, n_class_sample_combination = choose_n_classes(n)\n",
    "        sample_combination = n_class_sample_combination.copy()\n",
    "    else:\n",
    "        sample_combination = class_sample_combination.copy()\n",
    "\n",
    "    cluster_dict = {}\n",
    "    vector_dict = {}\n",
    "    class_num = 0\n",
    "\n",
    "    # get random first sample\n",
    "    first = random.choice(sample_combination)\n",
    "    # remove it from the combinations\n",
    "    sample_combination.remove(first)\n",
    "\n",
    "    # get class from sample\n",
    "    sample_class, sample_position = first\n",
    "\n",
    "    # create a dict from the first sample\n",
    "    cluster_dict[class_num] = [sample_class]\n",
    "\n",
    "    # create a dict which will contain the clustered vector embeddings, it will be used to calculate the class mean\n",
    "    vector_dict[class_num] = [embeddings[sample_class, sample_position]]\n",
    "\n",
    "    while sample_combination != []:\n",
    "\n",
    "        random_cls, random_pos = random.choice(sample_combination)\n",
    "        sample_combination.remove((random_cls, random_pos))\n",
    "\n",
    "        random_sample = embeddings[random_cls, random_pos]\n",
    "\n",
    "        biggest_sim = 0\n",
    "        # iterate the present clusters to choose the best one\n",
    "        for key in vector_dict:\n",
    "            cls_mean = get_mean(vector_dict[key])\n",
    "\n",
    "            # compare the sample with all clusters mean\n",
    "            cls_sim = cosine_sim(random_sample, cls_mean)\n",
    "\n",
    "            # if bigger than the actual, update the biggest similarity and change the biggest similarity cluster\n",
    "            if cls_sim > biggest_sim:\n",
    "                biggest_sim = cls_sim\n",
    "                best_cluster = key\n",
    "\n",
    "        # if the biggest similarity does not exceed the threshold, create new cluster with that sample\n",
    "        if biggest_sim < thresh:\n",
    "            class_num += 1\n",
    "            cluster_dict[class_num] = [random_cls]\n",
    "            vector_dict[class_num] = [embeddings[random_cls, random_pos]]\n",
    "\n",
    "        # if the biggest similarity exceeds the threshold, add it to the best cluster\n",
    "        else:\n",
    "            cluster_dict[best_cluster].append(random_cls)\n",
    "            vector_dict[best_cluster].append(embeddings[random_cls, random_pos])\n",
    "\n",
    "    return cluster_dict, vector_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JVBuH_vo-3CH"
   },
   "outputs": [],
   "source": [
    "def get_labels_from_clustering(cluster_dict):\n",
    "    labels_true, labels_pred = [], []\n",
    "    for key in cluster_dict:\n",
    "        first_value = cluster_dict[key][0]\n",
    "        labels_true += ([first_value] * len(cluster_dict[key]))\n",
    "        labels_pred += (cluster_dict[key])\n",
    "\n",
    "    return adjusted_rand_score(labels_true, labels_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D-Voqij8aUAJ",
    "outputId": "5e85be9f-cb33-4f40-b831-32f8cb83fc16"
   },
   "outputs": [],
   "source": [
    "cd, vd = cluster_no_finetuning(0.96, choose_n = False, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iMRiwKmU5DQF"
   },
   "outputs": [],
   "source": [
    "def compute_nmi_ari(clusterings):\n",
    "    labels_dict = {}\n",
    "    labels_dict_present = {}\n",
    "    num=0\n",
    "\n",
    "    for cluster in clusterings:\n",
    "        values = clusterings[cluster]\n",
    "\n",
    "        if str(values[0]) not in labels_dict_present.keys():\n",
    "            labels_dict_present[str(values[0])] = clusterings[cluster]\n",
    "        else:\n",
    "            labels_dict_present[str(values[0])+f\"_{num}\"] = clusterings[cluster]\n",
    "            num+=1\n",
    "            \n",
    "    for cluster in clusterings:\n",
    "        values = clusterings[cluster]\n",
    "\n",
    "        for value in values:\n",
    "            if value not in labels_dict.keys():\n",
    "                labels_dict[value] = []\n",
    "                \n",
    "    bad_cl = 350\n",
    "    false_cluster = False\n",
    "    for key in labels_dict_present:\n",
    "        values = labels_dict_present[key]\n",
    "        false_cluster = False\n",
    "        for value in values:\n",
    "            if len(key.split(\"_\")) == 2:\n",
    "                labels_dict[value].append(bad_cl)\n",
    "                false_cluster = True\n",
    "            else:\n",
    "                labels_dict[value].append(key)\n",
    "\n",
    "        if false_cluster:\n",
    "            bad_cl+=1\n",
    "            \n",
    "    \n",
    "    labels = [[x]*10 for x in labels_dict.keys()]\n",
    "    labels = [item for sublist in labels for item in sublist]\n",
    "\n",
    "    preds = [labels_dict[x] for x in labels_dict]\n",
    "    preds = [item for sublist in preds for item in sublist]\n",
    "    \n",
    "    ari = adjusted_rand_score(labels, preds)\n",
    "    nmi = normalized_mutual_info_score(labels, preds)\n",
    "    \n",
    "    return nmi, ari"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_thresholds = [0.75, 0.78, 0.79, 0.80, 0.81, 0.82, 0.83, 0.84, 0.85, 0.9]\n",
    "cluster_classes = [10, 50, 100, 338]\n",
    "\n",
    "for t in cluster_thresholds:\n",
    "    for c in cluster_classes:\n",
    "        \n",
    "        list_nmi, list_ari = [], []\n",
    "        for _ in range(10):\n",
    "            cd, _ = cluster_no_finetuning(t, choose_n = True, n = c)\n",
    "            nmi, ari = compute_nmi_ari(cd)\n",
    "            list_nmi.append(nmi)\n",
    "            list_ari.append(ari)\n",
    "                        \n",
    "        print(f\"Metrics for threshold {t} and for {c} classes\") \n",
    "        print(f\"mean nmi {np.mean(list_nmi)} +- {np.std(list_nmi)}\")\n",
    "        print(f\"mean ari {np.mean(list_ari)} +- {np.std(list_ari)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-VrAgWdCFmy3"
   },
   "outputs": [],
   "source": [
    "# loading\n",
    "\n",
    "image_folder_files = os.listdir(main_folder)\n",
    "image_folder_files = [img.split('.')[0] for img in image_folder_files]\n",
    "image_folder_files.sort()\n",
    "\n",
    "f_dict = {}\n",
    "for file_class in os.listdir(main_folder):\n",
    "    f_dict[file_class] = []\n",
    "\n",
    "with open('test.npy', 'rb') as f:\n",
    "    for key in f_dict:\n",
    "        f_dict[key] = np.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wna0fiHjJeqW"
   },
   "outputs": [],
   "source": [
    "# saving\n",
    "\n",
    "f_dict = dict(sorted(f_dict.items()))\n",
    "\n",
    "with open('test.npy', 'wb') as f:\n",
    "    for key in f_dict:\n",
    "        np.save(f, f_dict[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PQfcm7rA_c8D"
   },
   "outputs": [],
   "source": [
    "# new class\n",
    "\n",
    "new_class = np.empty((0, 2208))\n",
    "new_class = np.append(new_class, np.array([class_embedding]), axis = 0)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
